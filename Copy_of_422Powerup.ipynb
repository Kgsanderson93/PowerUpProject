{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kgsanderson93/PowerUpProject/blob/main/Copy_of_422Powerup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoLB_kZ574N2"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime\n",
        "import os\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_aywsX4URhI",
        "outputId": "fd109014-6215-4df0-cbe9-cafc9477dfb3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.2-py2.py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->ipython-autotime)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.13)\n",
            "Installing collected packages: jedi, ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.2 jedi-0.19.1\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n",
            "time: 17.4 s (started: 2024-01-23 14:08:32 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit"
      ],
      "metadata": {
        "id": "3Jcf4fmvVVim",
        "outputId": "d31b1b45-3ce0-4e7c-b422-7968f9006757",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 420 µs (started: 2024-01-23 14:08:51 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CyEINwm4L0-s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36e12215-94ae-49c0-a363-a1a2f9dd32a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25htime: 20.5 s (started: 2024-01-23 14:08:51 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from prophet import Prophet\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "plt.style.use('fivethirtyeight')\n",
        "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
        "\n",
        "import xgboost as xgb\n",
        "color_pal = sns.color_palette()\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "from matplotlib.pylab import rcParams\n",
        "\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "!pip install pmdarima --quiet\n",
        "import pmdarima as pm\n",
        "from pmdarima.utils import tsdisplay\n",
        "from scipy.stats import normaltest\n",
        "\n",
        "\n",
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    \"\"\"Calculates MAPE given y_true and y_pred\"\"\"\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "errorcmp=pd.DataFrame(columns=['Name', 'MSE', 'MAE', 'MAPE', 'Elapsed_Time'])\n",
        "def modelcmp(m1,m2):\n",
        "  MSE=np.sqrt(mean_squared_error(y_true=m1,\n",
        "                   y_pred=m2))\n",
        "  MAE=mean_absolute_error(y_true=m1,\n",
        "                   y_pred=m2)\n",
        "  MAPE=mean_absolute_percentage_error(y_true=m1,\n",
        "                   y_pred=m2)\n",
        "  return MSE, MAE, MAPE\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.api.types import CategoricalDtype\n",
        "\n",
        "cat_type = CategoricalDtype(categories=['Monday','Tuesday',\n",
        "                                        'Wednesday',\n",
        "                                        'Thursday','Friday',\n",
        "                                        'Saturday','Sunday'],\n",
        "                            ordered=True)\n",
        "\n",
        "def create_features(df, label=None):\n",
        "    \"\"\"\n",
        "    Creates time series features from datetime index.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    df['date'] = df.index\n",
        "    df['hour'] = df['date'].dt.hour\n",
        "    df['dayofweek'] = df['date'].dt.dayofweek\n",
        "    df['weekday'] = df['date'].dt.day_name()\n",
        "    df['weekday'] = df['weekday'].astype(cat_type)\n",
        "    df['quarter'] = df['date'].dt.quarter\n",
        "    df['month'] = df['date'].dt.month\n",
        "    df['year'] = df['date'].dt.year\n",
        "    df['dayofyear'] = df['date'].dt.dayofyear\n",
        "    df['dayofmonth'] = df['date'].dt.day\n",
        "    df['weekofyear'] = df['date'].dt.weekofyear\n",
        "    df['date_offset'] = (df.date.dt.month*100 + df.date.dt.day - 320)%1300\n",
        "    df['season'] = pd.cut(df['date_offset'], [0, 300, 602, 900, 1300],\n",
        "                          labels=['Spring', 'Summer', 'Fall', 'Winter']\n",
        "                   )\n",
        "    X = df[['hour','dayofweek','quarter','month','year',\n",
        "           'dayofyear','dayofmonth','weekofyear','weekday',\n",
        "           'season']]\n",
        "    if label:\n",
        "        y = df[[label]]\n",
        "        return X, y\n",
        "    return X\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rp_24XlF8CY2",
        "outputId": "6de856f6-003b-43d8-f2ef-b8475a9fd0ff"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 16.1 ms (started: 2024-01-23 14:09:11 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_lags(df):\n",
        "    target_map = df['PJME_MW'].to_dict()\n",
        "    df['lag1'] = (df.index - pd.Timedelta('364 days')).map(target_map) # 364 is divisible by 7, so the lagged days of the week line up with the days fo the week\n",
        "    df['lag2'] = (df.index - pd.Timedelta('728 days')).map(target_map)\n",
        "    df['lag3'] = (df.index - pd.Timedelta('1092 days')).map(target_map)\n",
        "    return df\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMmhQ4zbGIN1",
        "outputId": "bb510d0f-2bf0-4834-df2a-65302491a223"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 12.5 ms (started: 2024-01-23 14:09:12 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(outlier, lags=False):\n",
        "\n",
        "\n",
        "  df= pd.read_csv('PJME_hourly.csv',\n",
        "                   index_col=[0],\n",
        "                  parse_dates=[0])\n",
        "  if lags==True:\n",
        "    df=add_lags(df)\n",
        "  if outlier==True:\n",
        "    df = df.loc[df['PJME_MW'] > 19500].copy()\n",
        "  tss = TimeSeriesSplit(n_splits=5, test_size=24*365*1, max_train_size=24*365*1)\n",
        "  df = df.sort_index() # df needs to be sorted for TimeSeriesSplit\n",
        "  ig, axes = plt.subplots(5, 1, figsize=(15,15), sharex=True)\n",
        "  fold = 0\n",
        "  train_set=[]\n",
        "  test_set=[]\n",
        "  for train_idx, val_idx in tss.split(df):\n",
        "    train = df.iloc[train_idx]\n",
        "    test = df.iloc[val_idx]\n",
        "    train_set.append(train)\n",
        "    test_set.append(test)\n",
        "    train['PJME_MW'].plot(ax=axes[fold],\n",
        "                          label='Training Set',\n",
        "                          title=f'Train/Test Split Fold {fold}')\n",
        "\n",
        "    test['PJME_MW'].plot(ax=axes[fold],\n",
        "                         label='Test Set')\n",
        "\n",
        "    axes[fold].axvline(test.index.min(), color='black', ls='--')\n",
        "\n",
        "    fold += 1\n",
        "  train_x_set=[]\n",
        "  train_y_set=[]\n",
        "  test_x_set=[]\n",
        "  test_y_set=[]\n",
        "  for i in train_set:\n",
        "    X, y = create_features(i, label='PJME_MW')\n",
        "    train_x_set.append(X)\n",
        "    train_y_set.append(y)\n",
        "    features_and_target = pd.concat([X, y], axis=1)\n",
        "\n",
        "  for i in test_set:\n",
        "    X, y = create_features(i, label='PJME_MW')\n",
        "    test_x_set.append(X)\n",
        "    test_y_set.append(y)\n",
        "    features_and_target = pd.concat([X, y], axis=1)\n",
        "  return (train_set, test_set, train_x_set, train_y_set, test_x_set, test_y_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8IKDmYi41DG",
        "outputId": "f0bedbe6-e883-4fea-b019-19975986a081"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.87 ms (started: 2024-01-23 14:09:12 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "7MVl0EIuMknt",
        "outputId": "ac9c2aa5-489b-4d56-a56e-c9e7f85004dd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'PJME_hourly.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-7fde69cd4cc8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-d26cea698b63>\u001b[0m in \u001b[0;36msplit_data\u001b[0;34m(outlier, lags)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   df= pd.read_csv('PJME_hourly.csv',\n\u001b[0m\u001b[1;32m      5\u001b[0m                    \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                   parse_dates=[0])\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'PJME_hourly.csv'"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 815 ms (started: 2024-01-23 14:09:12 +00:00)\n"
          ]
        }
      ],
      "source": [
        "train_set, test_set, train_x_set, train_y_set, test_x_set, test_y_set=split_data(False, lags=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNp1o4iiMrHE"
      },
      "outputs": [],
      "source": [
        "def data_explore():\n",
        "  df= pd.read_csv('PJME_hourly.csv',\n",
        "                   index_col=[0],\n",
        "                  parse_dates=[0])\n",
        "  color_pal = sns.color_palette()\n",
        "  df.plot(style='.',\n",
        "          figsize=(18, 8),\n",
        "          ms=1,\n",
        "          color=color_pal[0],\n",
        "          title='PJME MW')\n",
        "  plt.show()\n",
        "  fig, ax = plt.subplots(figsize=(20, 8))\n",
        "  features, target=create_features(df, label=\"PJME_MW\")\n",
        "  features[\"PJME_MW\"]=target[\"PJME_MW\"]\n",
        "  sns.boxplot(data=features.dropna(),\n",
        "            x='weekday',\n",
        "            y='PJME_MW',\n",
        "            hue='season',\n",
        "            ax=ax,\n",
        "            linewidth=1)\n",
        "\n",
        "  ax.set_title('Power Use MW by Day of Week')\n",
        "  ax.set_xlabel('Day of Week')\n",
        "  ax.set_ylabel('Energy (MW)')\n",
        "  ax.legend(bbox_to_anchor=(1, 1))\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  import math\n",
        "  avg = df['PJME_MW'].mean()\n",
        "  stdev = math.sqrt(((df['PJME_MW'] - avg)**2).sum() / len(df))\n",
        "\n",
        "  df['PJME_MW'].hist(bins=100)\n",
        "\n",
        "  # Plot the 3rd standard deviation on the histogram\n",
        "  plt.axvline(avg + stdev*3, color='black')\n",
        "  plt.axvline(avg - stdev*3, color='black')\n",
        "\n",
        "  plt.show()\n",
        "  fig, ax = plt.subplots(figsize=(15, 8))\n",
        "  graph = sns.boxplot(data=features, x='hour', y='PJME_MW')\n",
        "  ax.set_title('MW by Hour')\n",
        "  graph.axhline(df['PJME_MW'].quantile(0.95))\n",
        "  graph.axhline(df['PJME_MW'].quantile(0.05))\n",
        "  plt.show()\n",
        "  fig, ax = plt.subplots(figsize=(15, 8))\n",
        "  graph = sns.boxplot(data=features, x='month', y='PJME_MW')\n",
        "  ax.set_title('MW by Month')\n",
        "  plt.axhline(avg + stdev*3, color='black')\n",
        "  plt.axhline(avg - stdev*3, color='black')\n",
        "  plt.show()\n",
        "  #Determine rolling statistics\n",
        "  df[\"rolling_avg_12hour\"] = df['PJME_MW'].rolling(window=12).mean() #window size 12 denotes 12 months, giving rolling mean at yearly level\n",
        "  df[\"rolling_std_12hour\"] = df['PJME_MW'].rolling(window=12).std()\n",
        "  df[\"rolling_avg_daily\"] = df['PJME_MW'].rolling(window=24).mean() #window size 12 denotes 12 months, giving rolling mean at yearly level\n",
        "  df[\"rolling_std_daily\"] = df['PJME_MW'].rolling(window=24).std()\n",
        "  df[\"rolling_avg_weekly\"] = df['PJME_MW'].rolling(window=168).mean() #window size 12 denotes 12 months, giving rolling mean at yearly level\n",
        "  df[\"rolling_std_weekly\"] = df['PJME_MW'].rolling(window=168).std()\n",
        "  df[\"rolling_avg_monthly\"] = df['PJME_MW'].rolling(window=744).mean() #window size 12 denotes 12 months, giving rolling mean at yearly level\n",
        "  df[\"rolling_std_monthly\"] = df['PJME_MW'].rolling(window=744).std()\n",
        "  df[\"rolling_avg_yearly\"] = df['PJME_MW'].rolling(window=8760).mean() #window size 12 denotes 12 months, giving rolling mean at yearly level\n",
        "  df[\"rolling_std_yearly\"] = df['PJME_MW'].rolling(window=8760).std()\n",
        "  plt.figure(figsize=(15,7))\n",
        "  plt.plot(df['PJME_MW'], color='#379BDB', label='Original')\n",
        "  plt.plot(df[\"rolling_avg_12hour\"], color='darkviolet', label='Rolling Mean 12hour')\n",
        "  plt.plot(df[\"rolling_std_12hour\"], color='darkorchid', label='Rolling Std_12hour')\n",
        "  plt.plot(df[\"rolling_avg_daily\"], color='#D22A0D', label='Rolling Mean Daily')\n",
        "  plt.plot(df[\"rolling_std_daily\"], color='#142039', label='Rolling Std Daily')\n",
        "  plt.plot(df[\"rolling_avg_weekly\"], color='#D67A0D', label='Rolling Mean Weekly')\n",
        "  plt.plot(df[\"rolling_std_weekly\"], color='#167039', label='Rolling Std Weekly')\n",
        "  plt.plot(df[\"rolling_avg_monthly\"], color='darkgreen', label='Rolling Mean Monthly')\n",
        "  plt.plot(df[\"rolling_std_monthly\"], color='green', label='Rolling Std Monthly')\n",
        "  plt.plot(df[\"rolling_avg_yearly\"], color='gold', label='Rolling Mean Yearly')\n",
        "  plt.plot(df[\"rolling_std_yearly\"], color='yellow', label='Rolling Std Yearly')\n",
        "  plt.legend(loc='best')\n",
        "  plt.title('Rolling Mean & Standard Deviation')\n",
        "  plt.show(block=False)\n",
        "\n",
        "  #Augmented Dickey–Fuller test:\n",
        "  print('Results of Dickey Fuller Test:')\n",
        "  dftest = adfuller(df['PJME_MW'], autolag='AIC')\n",
        "\n",
        "  dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
        "  for key,value in dftest[4].items():\n",
        "    dfoutput['Critical Value (%s)'%key] = value\n",
        "  print(dfoutput)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GB_VNoI5NDuY"
      },
      "outputs": [],
      "source": [
        "data_explore()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "\n"
      ],
      "metadata": {
        "id": "mb6_SjAoLCLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qliLngBKWZpm"
      },
      "source": [
        "#ProphetModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "from datetime import timedelta\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "kdqt0XGC7AD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install neuralprophet[live] --quiet\n",
        "from neuralprophet import NeuralProphet\n",
        "from neuralprophet import set_random_seed\n",
        "set_random_seed(0)"
      ],
      "metadata": {
        "id": "mMHzXZpe4NSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def buildNeural(outlier, name):\n",
        "   start_time = timeit.default_timer()\n",
        "   nameset=name\n",
        "   train_set, test_set, train_x_set, train_y_set, test_x_set, test_y_set=split_data(outlier)\n",
        "   x = len(test_set)\n",
        "   i=0\n",
        "   while i < x:\n",
        "    name=nameset\n",
        "    pjme_train_prophet = train_set[i].reset_index() \\\n",
        "    .rename(columns={'Datetime':'ds',\n",
        "                     'PJME_MW':'y'})\n",
        "    print(pjme_train_prophet.shape)\n",
        "    pjme_test_prophet = test_set[i].reset_index() \\\n",
        "    .rename(columns={'Datetime':'ds',\n",
        "                     'PJME_MW':'y'})\n",
        "    print( pjme_test_prophet.shape)\n",
        "    model = NeuralProphet()\n",
        "    metrics=model.fit(df=pjme_train_prophet, validation_df= pjme_test_prophet, freq=\"H\", progress=\"plot-all\")\n",
        "    metrics[-1:]\n",
        "    future = model.make_future_dataframe(df=pjme_train_prophet, periods=len(test_set[i]), n_historic_predictions=True)\n",
        "    forecast = model.predict(df=future)\n",
        "    fig_forecast = model.plot(forecast)\n",
        "\n"
      ],
      "metadata": {
        "id": "UohniMDV4aZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set, test_set, train_x_set, train_y_set, test_x_set, test_y_set=split_data(False)\n",
        "pjme_train_prophet = train_set[0].reset_index() \\\n",
        "    .rename(columns={'Datetime':'ds',\n",
        "                     'PJME_MW':'y'})\n",
        "print(pjme_train_prophet.shape)\n",
        "pjme_test_prophet = test_set[0].reset_index() \\\n",
        "    .rename(columns={'Datetime':'ds',\n",
        "                     'PJME_MW':'y'})\n",
        "print(pjme_test_prophet.shape)\n"
      ],
      "metadata": {
        "id": "q8Mdh9fu-rP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter Options\n",
        "param_grid = {\n",
        "    'changepoints_range': [0.95, 0.975, 0.99, 0.995, 0.999],\n",
        "    'n_lags':[2,4],\n",
        "    'newer_samples_weight':[2,4],\n",
        "    'n_forecasts':[1,2],\n",
        "    'learning_rate':[0.02, .04]\n",
        "}\n",
        "\n",
        "# Generate all combinations of parameters\n",
        "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
        "results = []  # Store the RMSEs for each params here\n",
        "\n",
        "# Use cross validation to evaluate all parameters\n",
        "for params in all_params:\n",
        "    m = NeuralProphet(**params, epochs=10, batch_size=280)\n",
        "    metrics4 = m.fit(df=pjme_train_prophet , validation_df=pjme_test_prophet , freq=\"H\")\n",
        "    results.append(dict({\"RMSE_val\": metrics4['RMSE_val'].min(), \"RMSE_train\": metrics4['RMSE'][metrics4['RMSE_val'].idxmin()], \"score_epoch_number\": metrics4['RMSE_val'].idxmin()}, **params))\n"
      ],
      "metadata": {
        "id": "TFVqburR9LQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m=buildNeural(False, \"Neural\")"
      ],
      "metadata": {
        "id": "7LLLSZ7r4aNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aF9fy9Wq6GS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71kSCpReNIb_"
      },
      "outputs": [],
      "source": [
        "def buildProphet(outlier, name):\n",
        "  start_time = timeit.default_timer()\n",
        "  nameset=name\n",
        "  train_set, test_set, train_x_set, train_y_set, test_x_set, test_y_set=split_data(outlier)\n",
        "\n",
        "  x = len(test_set)\n",
        "  i=0\n",
        "  while i < x:\n",
        "    name=nameset\n",
        "  # Plot train and test so you can see where we have split\n",
        "    test_set[i].rename(columns={'PJME_MW': 'TEST SET'}).join(train_set[i].rename(columns={'PJME_MW': 'TRAINING SET'}),how='outer') \\\n",
        "    .plot(figsize=(20, 8), title='PJM East', style='.', ms=1)\n",
        "    plt.show()\n",
        "  # Format data for prophet model using ds and y\n",
        "    pjme_train_prophet = train_set[i].reset_index() \\\n",
        "    .rename(columns={'Datetime':'ds',\n",
        "                     'PJME_MW':'y'})\n",
        "    print(pjme_train_prophet.shape)\n",
        "    model = Prophet()\n",
        "    model.fit(pjme_train_prophet)\n",
        "  # Predict on test set with model\n",
        "    pjme_test_prophet = test_set[i].reset_index() \\\n",
        "    .rename(columns={'Datetime':'ds',\n",
        "                     'PJME_MW':'y'})\n",
        "\n",
        "    pjme_test_fcst = model.predict(pjme_test_prophet)\n",
        "    fig, ax = plt.subplots(figsize=(20, 16))\n",
        "    fig = model.plot(pjme_test_fcst, ax=ax)\n",
        "    ax.set_title('Prophet Forecast')\n",
        "    fig.savefig('forecast.png')\n",
        "    plt.show()\n",
        "    fig = model.plot_components(pjme_test_fcst)\n",
        "    fig.savefig('components.png')\n",
        "    plt.show()\n",
        "    # Plot the forecast with the actuals\n",
        "    try: f\n",
        "    except NameError: f = None\n",
        "    if f is not None:\n",
        "      del f\n",
        "    try: ax\n",
        "    except NameError: ax = None\n",
        "    if ax is not None:\n",
        "      del ax\n",
        "    f, ax = plt.subplots(figsize=(24, 16))\n",
        "    ax.scatter(test_set[i].index, test_set[i]['PJME_MW'], color='r')\n",
        "    fig = model.plot(pjme_test_fcst, ax=ax)\n",
        "\n",
        "    date_start = datetime.datetime(2015,1,1)\n",
        "    date_end = test_set[i].index[-1]\n",
        "    ax.set(xlim = [date_start,date_end])\n",
        "    fig.savefig('compare.png')\n",
        "    fig, ax = plt.subplots(figsize=(24, 12))\n",
        "\n",
        "    ax.scatter(test_set[i].index, test_set[i]['PJME_MW'], color='r')\n",
        "\n",
        "    fig = model.plot(pjme_test_fcst, ax=ax)\n",
        "    ax.set_xbound(lower=pd.to_datetime('01-01-2015'),\n",
        "              upper=pd.to_datetime('02-01-2015'))\n",
        "\n",
        "    ax.set_ylim(0, 60000)\n",
        "\n",
        "    plot = plt.suptitle('January 2015 Forecast vs Actuals')\n",
        "    fig.savefig('comparemonth.png')\n",
        "    # Plot the forecast with the actuals\n",
        "    f, ax = plt.subplots(figsize=(24, 12))\n",
        "\n",
        "    ax.scatter(test_set[i].index, test_set[i]['PJME_MW'], color='r')\n",
        "\n",
        "    fig = model.plot(pjme_test_fcst, ax=ax)\n",
        "    ax.set_xbound(lower=pd.to_datetime('01-01-2017'), upper=pd.to_datetime('01-08-2017'))\n",
        "    ax.set_ylim(0, 60000)\n",
        "    ax.set_title('First Week of January Forecast vs Actuals')\n",
        "    fig.savefig('compareweek.png')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    MSE,MAE,MAPE=modelcmp(test_set[i]['PJME_MW'],pjme_test_fcst['yhat'])\n",
        "    name=name+str(i)\n",
        "    elapsed = timeit.default_timer() - start_time\n",
        "\n",
        "    new_row=[name,MSE,MAE,MAPE,elapsed]\n",
        "    errorcmp.loc[len(errorcmp.index)]=new_row\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    cal = calendar()\n",
        "    holidays = cal.holidays(start=train_set[i].index.min(),\n",
        "                        end=test_set[i].index.max(),\n",
        "                        return_name=True)\n",
        "    holiday_df = pd.DataFrame(data=holidays,\n",
        "                          columns=['holiday'])\n",
        "    holiday_df = holiday_df.reset_index().rename(columns={'index':'ds'})\n",
        "    model_with_holidays = Prophet(holidays=holiday_df)\n",
        "    model_with_holidays.fit(pjme_train_prophet)\n",
        "    # Predict on training set with model\n",
        "    pjme_test_fcst_with_hols = \\\n",
        "    model_with_holidays.predict(df=pjme_test_prophet)\n",
        "    MSE,MAE,MAPE=modelcmp(test_set[i]['PJME_MW'],pjme_test_fcst_with_hols['yhat'])\n",
        "    elapsed = timeit.default_timer() - start_time\n",
        "    new_row=[name+'holiday',\n",
        "          MSE,MAE,MAPE, elapsed]\n",
        "    errorcmp.loc[len(errorcmp.index)]=new_row\n",
        "    i=i+1\n",
        "  return model, model_with_holidays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtSCIZkqlv0n"
      },
      "outputs": [],
      "source": [
        "model, model_with_holidays=buildProphet(False, 'ProphetOrig')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prophet - outliers"
      ],
      "metadata": {
        "id": "fgt5gMQhPhnz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ln6KgFTNnKhv"
      },
      "outputs": [],
      "source": [
        "model=buildProphet(True,'ProphetOrigNO')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEkLLyygoa3U"
      },
      "outputs": [],
      "source": [
        "errorcmp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV0PaRNPWn5l"
      },
      "source": [
        "#XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsCdh6gXX3TV"
      },
      "outputs": [],
      "source": [
        "def xgbmodel(name, outlier=True):\n",
        "  df= pd.read_csv('PJME_hourly.csv',\n",
        "                   index_col=[0],\n",
        "                  parse_dates=[0])\n",
        "  if outlier==True:\n",
        "    df = df.loc[df['PJME_MW'] > 19500].copy()\n",
        "\n",
        "  df, y = create_features(df, \"PJME_MW\")\n",
        "  df[\"PJME_MW\"]=y[\"PJME_MW\"]\n",
        "  df=add_lags(df)\n",
        "  tss = TimeSeriesSplit(n_splits=5, test_size=24*365*1)\n",
        "  df = df.sort_index()\n",
        "\n",
        "\n",
        "  ##preprocess\n",
        "  FEATURES = ['hour','dayofweek','quarter','month','year',\n",
        "           'dayofyear','dayofmonth','weekofyear']\n",
        "  TARGET = ['PJME_MW']\n",
        "\n",
        "  nameset=name\n",
        "  start_time = timeit.default_timer()\n",
        "\n",
        "\n",
        "  fold = 0\n",
        "  preds = []\n",
        "  scores = []\n",
        "\n",
        "  for train_idx, val_idx in tss.split(df):\n",
        "    train = df.iloc[train_idx]\n",
        "    test = df.iloc[val_idx]\n",
        "\n",
        "    name=nameset\n",
        "    X_train = train[FEATURES]\n",
        "    y_train = train[TARGET]\n",
        "\n",
        "    X_test = test[FEATURES]\n",
        "    y_test = test[TARGET]\n",
        "    reg = xgb.XGBRegressor(base_score= 0.5, early_stopping_rounds= 25, learning_rate= 0.07, max_depth= 4, n_estimators= 100)\n",
        "    reg.fit(X_train, y_train,\n",
        "            eval_set=[(X_train, y_train), (X_test, y_test)],\n",
        "            verbose=100)\n",
        "\n",
        "    y_pred = reg.predict(X_test)\n",
        "    preds.append(y_pred)\n",
        "    score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    scores.append(score)\n",
        "    name=name+str(fold)\n",
        "    tryme=pd.DataFrame()\n",
        "    data={'PJME_MW':y_test[\"PJME_MW\"],'predictions':reg.predict(X_test)}\n",
        "    tryme= pd.DataFrame(data,index=y_test.index)\n",
        "    MSE,MAE,MAPE=modelcmp(tryme[\"PJME_MW\"],tryme[\"predictions\"])\n",
        "    elapsed = timeit.default_timer() - start_time\n",
        "    new_row=[name,\n",
        "            MSE,MAE,MAPE,elapsed]\n",
        "    errorcmp.loc[len(errorcmp.index)]=new_row\n",
        "    fold=fold+1\n",
        "    y_train['PJME_MW'].plot(style='k', figsize=(10,5), label = 'train')\n",
        "    tryme['PJME_MW'].plot(style='b', figsize=(10,5), label = 'test')\n",
        "    tryme['predictions'].plot(style='r', figsize=(10,5), label = 'prediction')\n",
        "    plt.title('MW PReds')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "  print(f'Score across folds {np.mean(scores):0.4f}')\n",
        "  print(f'Fold scores:{scores}')\n",
        "  print('Average score:', sum(scores)/len(scores))\n",
        "  fi = pd.DataFrame(data=reg.feature_importances_,\n",
        "             index=reg.feature_names_in_,\n",
        "             columns=['importance'])\n",
        "  fi.sort_values('importance').plot(kind='barh', title='Feature Importance')\n",
        "\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "  return reg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEE7l4sIu6Yj"
      },
      "outputs": [],
      "source": [
        "model2=xgbmodel('xgboost.01 bias.5', params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEk3CcWZvfJq"
      },
      "outputs": [],
      "source": [
        "errorcmp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaTH2gkLOxOu"
      },
      "source": [
        "#SARIMA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgNKbzFrW9vT"
      },
      "outputs": [],
      "source": [
        "def forecast_one_step():\n",
        "    fc, conf_int = model.predict(n_periods=1, return_conf_int=True)\n",
        "    return (\n",
        "        fc.tolist()[0],\n",
        "        np.asarray(conf_int).tolist()[0])\n",
        "def plot_forecasts(y_train, y_test, forecasts, title, figsize=(8, 12)):\n",
        "    x = np.arange(y_train.shape[0] + forecasts.shape[0])\n",
        "\n",
        "    fig, axes = plt.subplots(2, 1, sharex=False, figsize=figsize)\n",
        "\n",
        "    # Plot the forecasts\n",
        "    axes[0].plot(x[:y_train.shape[0]], y_train, c='b')\n",
        "    axes[0].plot(x[y_train.shape[0]:], forecasts, c='g')\n",
        "    axes[0].set_xlabel(f'Sunspots (RMSE={np.sqrt(mse(y_test, forecasts)):.3f})')\n",
        "    axes[0].set_title(title)\n",
        "\n",
        "    # Plot the residuals\n",
        "    resid = y_test - forecasts\n",
        "    _, p = normaltest(resid)\n",
        "    axes[1].hist(resid, bins=15)\n",
        "    axes[1].axvline(0, linestyle='--', c='r')\n",
        "    axes[1].set_title(f'Residuals (p={p:.3f})')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def Sarima_model(period, outlier=False):\n",
        "    start_time=timeit.default_timer()\n",
        "    train_set, test_set, train_x_set, train_y_set, test_x_set, test_y_set=split_data(outlier)\n",
        "\n",
        "    x=len(train_set)\n",
        "    i=0\n",
        "    name=\"SARIMA Period=\"+str(period)+\"Train_set=\"+str(i)\n",
        "    while i<x:\n",
        "\n",
        "      fit = pm.auto_arima(train_y_set[i], m=period, trace=True, suppress_warnings=True)\n",
        "      normaltest(train_y_set[i])[1]\n",
        "      model=fit\n",
        "      forecasts = []\n",
        "      confidence_intervals = []\n",
        "      for new_ob in test_y_set[i][\"PJME_MW\"]:\n",
        "        fc, conf = forecast_one_step()\n",
        "        forecasts.append(fc)\n",
        "        confidence_intervals.append(conf)\n",
        "        model.update(new_ob)\n",
        "      plot_forecasts(train_y_set[i],test_y_set[i], forecasts, name)\n",
        "      MSE,MAE,MAPE=modelcmp(test_y_set[i], forecasts)\n",
        "      elapsed = timeit.default_timer() - start_time\n",
        "      new_row=[name,MSE,MAE,MAPE,elapsed]\n",
        "      errorcmp.loc[len(errorcmp.index)]=new_row\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv('PJME_hourly.csv',\n",
        "                   index_col=[0],\n",
        "                  parse_dates=[0])\n",
        "pm.plot_acf(df)\n",
        "from pmdarima.arima.stationarity import ADFTest\n",
        "\n",
        "# Test whether we should difference at the alpha=0.05\n",
        "# significance level\n",
        "adf_test = ADFTest(alpha=0.05)\n",
        "p_val, should_diff = adf_test.should_diff(df)  # (0.01, False)\n",
        "print(should_diff, p_val)\n",
        "train, test = df[:150], df[150:]\n",
        "m1 = pm.auto_arima(train, error_action='ignore', seasonal=True, m=1)\n",
        "m12 = pm.auto_arima(train, error_action='ignore', seasonal=True, m=12)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 8))\n",
        "x = np.arange(test.shape[0])\n",
        "\n",
        "# Plot m=1\n",
        "axes[0].scatter(x, test, marker='x')\n",
        "axes[0].plot(x, m1.predict(n_periods=test.shape[0]))\n",
        "axes[0].set_title('Test samples vs. forecasts (m=1)')\n",
        "\n",
        "# Plot m=12\n",
        "axes[1].scatter(x, test, marker='x')\n",
        "axes[1].plot(x, m12.predict(n_periods=test.shape[0]))\n",
        "axes[1].set_title('Test samples vs. forecasts (m=12)')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8cAIDEv-W3mM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m12 = pm.auto_arima(train, error_action='ignore', seasonal=True, m=24)\n"
      ],
      "metadata": {
        "id": "0YFhrDauYAOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 8))\n",
        "x = np.arange(test.shape[0])\n",
        "\n",
        "# Plot m=1\n",
        "axes[0].scatter(x, test, marker='x')\n",
        "axes[0].plot(x, m1.predict(n_periods=test.shape[0]))\n",
        "axes[0].set_title('Test samples vs. forecasts (m=1)')\n",
        "\n",
        "# Plot m=12\n",
        "axes[1].scatter(x, test, marker='x')\n",
        "axes[1].plot(x, m12.predict(n_periods=test.shape[0]))\n",
        "axes[1].set_title('Test samples vs. forecasts (m=12)')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "IFe5HuPoYF1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n"
      ],
      "metadata": {
        "id": "SKQedi7JZtEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.plotting import autocorrelation_plot\n",
        "df= pd.read_csv('PJME_hourly.csv',\n",
        "                   index_col=[0],\n",
        "                  parse_dates=[0])\n",
        "autocorrelation_plot(df)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "b0TmV9MiYfAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Sarima_model(1)\n",
        "Sarima_model(24)\n",
        "Sarima_model(168)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F-rVRiq6Qufk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean squared error: 0.34238951346274243\n",
        "# SMAPE: 0.9825490519101439"
      ],
      "metadata": {
        "id": "i4Ld_77Y0ljp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQL-04gQQtjC"
      },
      "source": [
        "#Arima"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDQSDbJgQyVR"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "plt.style.use('ggplot')\n",
        "plt.style.use('fivethirtyeight')\n",
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = 10, 6\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.graphics.tsaplots import plot_predict\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "%pip install pmdarima --quiet\n",
        "from pmdarima.arima import auto_arima\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import math\n",
        "\n",
        "df=pd.read_csv('PJME_hourly.csv',\n",
        "                   index_col=[0],\n",
        "                  parse_dates=[0])\n",
        "df = df.sort_index()\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIr8GGiiTwEb"
      },
      "outputs": [],
      "source": [
        "df[[\"PJME_MW\"]].plot(subplots=True, layout=(2,1));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYimAiazbRlq"
      },
      "outputs": [],
      "source": [
        "#Test for stationarity\n",
        "\n",
        "def test_stationarity(timeseries):\n",
        "    #Determing rolling statistics\n",
        "    rolmean = timeseries.rolling(365).mean()\n",
        "    rolstd = timeseries.rolling(365).std()\n",
        "    #Plot rolling statistics:\n",
        "    plt.plot(timeseries, color='blue',label='Original')\n",
        "    plt.plot(rolmean, color='red', label='Rolling Mean')\n",
        "    plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
        "    plt.legend(loc='best')\n",
        "    plt.title('Rolling Mean and Standard Deviation')\n",
        "    plt.show(block=False)\n",
        "\n",
        "    print(\"Results of dickey fuller test\")\n",
        "    adft = adfuller(timeseries,autolag='AIC')\n",
        "    # output for dft will give us without defining what the values are.\n",
        "    # hence we manually write what values does it explains using a for loop\n",
        "    output = pd.Series(adft[0:4],index=['Test Statistics','p-value','No. of lags used','Number of observations used'])\n",
        "    for key,values in adft[4].items():\n",
        "        output['critical value (%s)'%key] =  values\n",
        "    print(output)\n",
        "\n",
        "test_stationarity(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b50t31y7gkRN"
      },
      "outputs": [],
      "source": [
        "#split data into train and training set\n",
        "#TODO try hardcoding the split\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "#tscv = TimeSeriesSplit(n_splits=2, gap=20)\n",
        "train_data=df.loc['2010-01-01':'2014-01-01']\n",
        "test_data=df.loc['2014-01-05':'2016-01-01']\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.grid(True)\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Power Usage (MW)')\n",
        "plt.plot(train_data, 'green', label='Train data')\n",
        "plt.plot(test_data, 'blue', label='Test data')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ewbh2SjiliL"
      },
      "outputs": [],
      "source": [
        "model_autoARIMA = auto_arima(train_data, start_p=0, start_q=0,\n",
        "                      test='adf',       # use adftest to find optimal 'd'\n",
        "                      max_p=3, max_q=3, # maximum p and q\n",
        "                      m=12,            # frequency of series\n",
        "                      d=1,              # Override d\n",
        "                      seasonal=True,    # Yes Seasonality\n",
        "                      start_P=0,\n",
        "                      D=1,\n",
        "                      trace=True,\n",
        "                      error_action='ignore',\n",
        "                      suppress_warnings=True,\n",
        "                      stepwise=True)\n",
        "print(model_autoARIMA.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQgmzG8qU-e8"
      },
      "outputs": [],
      "source": [
        "model_autoARIMA.plot_diagnostics(figsize=(15,8))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9F4B8gYYVOa"
      },
      "outputs": [],
      "source": [
        "model = ARIMA(train_data, order=(3, 0, 1))\n",
        "model_fit = model.fit()\n",
        "print(model_fit.summary())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd = model_fit.predict(start=0, end=0)"
      ],
      "metadata": {
        "id": "YIqFDO-BMtwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd = model_fit.get_prediction(steps=len(test_data), alpha=0.05)\n",
        "print(pd.summary_frame())\n",
        "plt.plot(pd.predicted_mean)"
      ],
      "metadata": {
        "id": "lGFCufzZH-Yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forecast = model_fit.get_forecast(len(test_data), alpha=0.05)  # 95% confidence\n",
        "forecast.predicted_mean\n",
        "plt.plot(forecast.predicted_mean)"
      ],
      "metadata": {
        "id": "z1MXRNrnbsHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forecast\n",
        "fc = model_fit.get_forecast(len(test_data), alpha=0.05)  # 95% confidence\n",
        "test_data_frame = pd.DataFrame(test_data)\n",
        "fc_data_frame = pd.DataFrame(fc.predicted_mean)\n",
        "fc_data_frame.index = test_data_frame.index\n",
        "# fc_series = pd.Series(fc_data_frame)\n",
        "lower_series = pd.Series(fc.conf_int()['lower PJME_MW'], index=test_data.index)\n",
        "upper_series = pd.Series(fc.conf_int()['upper PJME_MW'], index=test_data.index)\n",
        "plt.figure(figsize=(12,5), dpi=100)\n",
        "plt.plot(train_data, label='training')\n",
        "plt.plot(test_data, color = 'blue', label='Actual Power Usage')\n",
        "plt.plot(fc_data_frame, color = 'orange', label='Predicted Power Usage')\n",
        "plt.fill_between(lower_series.index, lower_series, upper_series, color='k', alpha=.10)\n",
        "plt.title('PJME Power Usage')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Actual Power Usage (MW)')\n",
        "plt.legend(loc='upper left', fontsize=8)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1jjQwVLyEBnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyznWi3OYlYa"
      },
      "outputs": [],
      "source": [
        "# report performance\n",
        "mse = mean_squared_error(y, predictions)\n",
        "print('MSE: '+str(mse))\n",
        "mae = mean_absolute_error(y, predictions)\n",
        "print('MAE: '+str(mae))\n",
        "rmse = math.sqrt(mean_squared_error(y, predictions))\n",
        "print('RMSE: '+str(rmse))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmzK18e4YyTa"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16,8))\n",
        "plt.plot(df.index[-600:], df['PJME_MW'].tail(600), color='green', label = 'Train Power Usage')\n",
        "plt.plot(test_data.index, y, color = 'red', label = 'Real Power Usage')\n",
        "plt.plot(test_data.index, predictions, color = 'blue', label = 'Predicted Power Usage')\n",
        "plt.title('PJME Power Usage')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Power Usage (MW)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('arima_model.pdf')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##FUCKAROUND\n"
      ],
      "metadata": {
        "id": "dmE0MVmvPlYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import requests\n",
        "from io import BytesIO\n",
        "# Register converters to avoid warnings\n",
        "pd.plotting.register_matplotlib_converters()\n",
        "plt.rc(\"figure\", figsize=(16,8))\n",
        "plt.rc(\"font\", size=14)\n",
        "\n",
        "\n",
        "from matplotlib.pylab import rcParams\n",
        "\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "!pip install pmdarima --quiet\n",
        "import pmdarima as pm"
      ],
      "metadata": {
        "id": "qqIniW3rPnJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df=pd.read_csv('PJME_hourly.csv',\n",
        "                   index_col=[0],\n",
        "                  parse_dates=[0])\n",
        "df=df.sort_index()"
      ],
      "metadata": {
        "id": "K3R0ZSGsPvPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.fillna(df.mean(numeric_only=True).round(1), inplace=True)\n",
        "df.shape"
      ],
      "metadata": {
        "id": "ABrWuza8RlpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datetimeindex=pd.date_range('2002-01-01 01:00:00', periods=145366, tz='Australia/Adelaide', freq='H')"
      ],
      "metadata": {
        "id": "hiLaBh-9QFzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.index=datetimeindex"
      ],
      "metadata": {
        "id": "8IAj1tyWRbyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=df.loc['2010-01-01':'2014-01-01']\n",
        "test_data=df.loc['2014-01-05':'2016-01-01']\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.grid(True)\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Power Usage (MW)')\n",
        "plt.plot(train_data, 'green', label='Train data')\n",
        "plt.plot(test_data, 'blue', label='Test data')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "FrtnH4-7QBiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,7))\n",
        "plt.title(\"PJME_MW\")\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('MW')\n",
        "plt.plot(df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EM_wKFKfUfQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Determine rolling statistics\n",
        "train_data[\"rolling_avg\"] = train_data[\"PJME_MW\"].rolling(window=168).mean() #window size 12 denotes 12 months, giving rolling mean at yearly level\n",
        "train_data[\"rolling_std\"] = train_data[\"PJME_MW\"].rolling(window=168).std()\n",
        "\n",
        "#Plot rolling statistics\n",
        "plt.figure(figsize=(15,7))\n",
        "plt.plot(train_data[\"PJME_MW\"], color='#379BDB', label='Original')\n",
        "plt.plot(train_data[\"rolling_avg\"], color='#D22A0D', label='Rolling Mean')\n",
        "plt.plot(train_data[\"rolling_std\"], color='#142039', label='Rolling Std')\n",
        "plt.legend(loc='best')\n",
        "plt.title('Rolling Mean & Standard Deviation')\n",
        "plt.show(block=False)"
      ],
      "metadata": {
        "id": "yliWTDyGUq2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Augmented Dickey–Fuller test:\n",
        "print('Results of Dickey Fuller Test:')\n",
        "dftest = adfuller(train_data['PJME_MW'], autolag='AIC')\n",
        "\n",
        "dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
        "for key,value in dftest[4].items():\n",
        "    dfoutput['Critical Value (%s)'%key] = value\n",
        "\n",
        "print(dfoutput)"
      ],
      "metadata": {
        "id": "pUystSsmU6Q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "def newmodel(df, name, rate, bias):\n",
        "  tss = TimeSeriesSplit(n_splits=5, test_size=24*365*1)\n",
        "  df = df.sort_index() # df needs to be sorted for TimeSeriesSplit\n",
        "  ig, axes = plt.subplots(5, 1, figsize=(15,15), sharex=True)\n",
        "\n",
        "  fold = 0\n",
        "  for train_idx, val_idx in tss.split(df):\n",
        "    train = df.iloc[train_idx]\n",
        "    test = df.iloc[val_idx]\n",
        "\n",
        "    train['PJME_MW'].plot(ax=axes[fold],\n",
        "                          label='Training Set',\n",
        "                          title=f'Train/Test Split Fold {fold}')\n",
        "\n",
        "    test['PJME_MW'].plot(ax=axes[fold],\n",
        "                         label='Test Set')\n",
        "\n",
        "    axes[fold].axvline(test.index.min(), color='black', ls='--')\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "  fold = 0\n",
        "\n",
        "  preds = []\n",
        "  scores = []\n",
        "\n",
        "  for train_idx, val_idx in tss.split(df):\n",
        "    train = df.iloc[train_idx]\n",
        "    test = df.iloc[val_idx]\n",
        "\n",
        "    FEATURES = ['dayofyear', 'hour', 'dayofweek', 'quarter', 'month', 'year']\n",
        "    TARGET = 'PJME_MW'\n",
        "\n",
        "    X_train = train[FEATURES]\n",
        "    y_train = train[TARGET]\n",
        "\n",
        "    X_test = test[FEATURES]\n",
        "    y_test = test[TARGET]\n",
        "    reg = xgb.XGBRegressor(base_score=bias, booster='gbtree',\n",
        "                          n_estimators=1000,\n",
        "                          early_stopping_rounds=50,\n",
        "                          objective='reg:squarederror',\n",
        "                          max_depth=3,\n",
        "                          learning_rate=rate)\n",
        "    reg.fit(X_train, y_train,\n",
        "           eval_set=[(X_train, y_train), (X_test, y_test)],\n",
        "           verbose=100)\n",
        "\n",
        "    y_pred = reg.predict(X_test)\n",
        "    preds.append(y_pred)\n",
        "    score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    scores.append(score)\n",
        "  print(f'Score across folds {np.mean(scores):0.4f}')\n",
        "  print(f'Fold scores:{scores}')\n",
        "  print('Average score:', sum(scores)/len(scores))\n",
        "  fi = pd.DataFrame(data=reg.feature_importances_,\n",
        "             index=reg.feature_names_in_,\n",
        "             columns=['importance'])\n",
        "  fi.sort_values('importance').plot(kind='barh', title='Feature Importance')\n",
        "  plt.show()\n",
        "\n",
        "  test['prediction'] = reg.predict(X_test)\n",
        "  df = df.merge(test[['prediction']], how='left', left_index=True, right_index=True)\n",
        "  ax = df[['PJME_MW']].plot(figsize=(15, 5))\n",
        "  df['prediction'].plot(ax=ax, style='-')\n",
        "  plt.legend(['Truth Data', 'Predictions'])\n",
        "  ax.set_title('Raw Dat and Prediction')\n",
        "  plt.show()\n",
        "\n",
        "  ax = df.loc[(df.index > '04-01-2018') & (df.index < '04-08-2018')]['PJME_MW'] \\\n",
        "    .plot(figsize=(15, 5), title='Week Of Data')\n",
        "  df.loc[(df.index > '04-01-2018') & (df.index < '04-08-2018')]['prediction'] \\\n",
        "    .plot(style='.')\n",
        "  plt.legend(['Truth Data','Prediction'])\n",
        "  plt.show()\n",
        "  MSE,MAE,MAPE=modelcmp(test['PJME_MW'],test['prediction'])\n",
        "  new_row=[name,\n",
        "          MSE,MAE,MAPE]\n",
        "  errorcmp.loc[len(errorcmp.index)]=new_row\n",
        "\n",
        "\n",
        "  from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "  return reg"
      ],
      "metadata": {
        "id": "yvstJn01rGfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Standard ARIMA Model\n",
        "ARIMA_model = pm.auto_arima(train_data['PJME_MW'],\n",
        "                      start_p=1,\n",
        "                      start_q=1,\n",
        "                      test='adf', # use adftest to find optimal 'd'\n",
        "                      max_p=3, max_q=3, # maximum p and q\n",
        "                      m=1, # frequency of series (if m==1, seasonal is set to FALSE automatically)\n",
        "                      d=None,# let model determine 'd'\n",
        "                      seasonal=False, # No Seasonality for standard ARIMA\n",
        "                      trace=False, #logs\n",
        "                      error_action='warn', #shows errors ('ignore' silences these)\n",
        "                      suppress_warnings=True,\n",
        "                      stepwise=True)"
      ],
      "metadata": {
        "id": "tRJkgU2aVAPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ARIMA_model.plot_diagnostics(figsize=(15,12))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tabz5M80VIj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forecast(ARIMA_model, periods=17472):\n",
        "    # Forecast\n",
        "    n_periods = periods\n",
        "    fitted, confint = ARIMA_model.predict(n_periods=n_periods, return_conf_int=True)\n",
        "    index_of_fc = pd.date_range(train_data.index[-1] + pd.DateOffset(months=0), periods = n_periods, freq='H')\n",
        "    print(fitted)\n",
        "    # make series for plotting purpose\n",
        "    fitted_series = pd.Series(fitted, index=index_of_fc)\n",
        "    lower_series = pd.Series(confint[:, 0], index=index_of_fc)\n",
        "    upper_series = pd.Series(confint[:, 1], index=index_of_fc)\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(15,7))\n",
        "    plt.plot(df[\"PJME_MW\"], color='#1f76b4')\n",
        "    plt.plot(fitted, color='darkgreen')\n",
        "    plt.fill_between(lower_series.index,\n",
        "                    lower_series,\n",
        "                    upper_series,\n",
        "                    color='k', alpha=.15)\n",
        "\n",
        "    plt.title(\"ARIMA/SARIMA - Forecast of MW\")\n",
        "    plt.show()\n",
        "\n",
        "forecast(ARIMA_model)"
      ],
      "metadata": {
        "id": "dhx85YGIWL36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SARIMA_model = pm.auto_arima(df[\"PJME_MW\"], start_p=1, start_q=1,\n",
        "                         test='adf',\n",
        "                         max_p=3, max_q=3,\n",
        "                         m=168, #12 is the frequncy of the cycle\n",
        "                         start_P=0,\n",
        "                         seasonal=True, #set to seasonal\n",
        "                         d=None,\n",
        "                         D=1, #order of the seasonal differencing\n",
        "                         trace=False,\n",
        "                         error_action='ignore',\n",
        "                         suppress_warnings=True,\n",
        "                         stepwise=True)"
      ],
      "metadata": {
        "id": "4DgNNkOkXW4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SARIMA_model.plot_diagnostics(figsize=(15,12))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4ZGgUKC4ZgMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forecast(SARIMA_model)"
      ],
      "metadata": {
        "id": "q10mAA5nZiyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mod = sm.tsa.statespace.SARIMAX(df['PJME_MW'], order=(3,0,1), simple_differencing=True)\n",
        "res = mod.fit(disp=False)\n"
      ],
      "metadata": {
        "id": "yLw-8KlaP49R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['lnMW']=np.log(df['PJME_MW'])"
      ],
      "metadata": {
        "id": "TNKBpOVMTwqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mod2 = sm.tsa.statespace.SARIMAX(df['lnMW'], order=(3,0,1), simple_differencing=True)\n",
        "res2 = mod.fit(disp=False)"
      ],
      "metadata": {
        "id": "Vng8183mTtDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(res2.summary())\n"
      ],
      "metadata": {
        "id": "WroSYbIETK2W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}